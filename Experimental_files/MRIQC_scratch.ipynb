{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf7a29e0-d1e2-4586-a1ec-b6f53699891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "data_dir = \"/Users/quentin/Desktop/ML_MRIqc_DATASET/ML_Data/pics\"\n",
    "accepted_dir = os.path.join(data_dir, \"Accepted\")\n",
    "rejected_dir = os.path.join(data_dir, \"Rejected\")\n",
    "new_dir = \"/Users/quentin/Desktop/ML_MRIqc_DATASET/ML_Data/Cleaned\"\n",
    "\n",
    "accepted = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(accepted_dir)\n",
    "    for file in files if file.endswith(\".png\")\n",
    "]\n",
    "rejected = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(rejected_dir)\n",
    "    for file in files if file.endswith(\".png\")\n",
    "]\n",
    "\n",
    "# Rename the data because u were a lazy idiot and didn't want to originally rename the raw data\n",
    "def rename_files_in_folder(src_folder, dest_folder):\n",
    "    os.makedirs(dest_folder, exist_ok=True)  \n",
    "    for root, _, files in os.walk(src_folder):\n",
    "        folder_name = os.path.basename(root)  \n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_name = f\"{folder_name}_{file}\"\n",
    "                new_path = os.path.join(dest_folder, new_name)\n",
    "                shutil.copy(old_path, new_path)\n",
    "\n",
    "rename_files_in_folder(accepted_dir, os.path.join(new_dir, \"Accepted\"))\n",
    "rename_files_in_folder(rejected_dir, os.path.join(new_dir, \"Rejected\"))\n",
    "\n",
    "\n",
    "### train/test/validation data\n",
    "accepted_clean = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(os.path.join(new_dir, \"Accepted\"))\n",
    "    for file in files if file.endswith(\".png\")\n",
    "]\n",
    "rejected_clean = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(os.path.join(new_dir, \"Rejected\"))\n",
    "    for file in files if file.endswith(\".png\")\n",
    "]\n",
    "\n",
    "# 80% train, 10% test, 10% validation\n",
    "train_acc, temp_acc = train_test_split(accepted_clean, test_size=0.2, random_state=420)\n",
    "val_acc, test_acc = train_test_split(temp_acc, test_size=0.5, random_state=420)\n",
    "\n",
    "train_rej, temp_rej = train_test_split(rejected_clean, test_size=0.2, random_state=420)\n",
    "val_rej, test_rej = train_test_split(temp_rej, test_size=0.5, random_state=420)\n",
    "\n",
    "# helper function\n",
    "def create_split_folder(output_dir, data, class_name):\n",
    "    class_dir = os.path.join(output_dir, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    for path in data:\n",
    "        shutil.copy(path, class_dir)\n",
    "\n",
    "output_dir = \"/Users/quentin/Desktop/ML_MRIqc_DATASET/Ready_Data\"\n",
    "splits = {\n",
    "    \"train\": (train_acc, train_rej),\n",
    "    \"val\": (val_acc, val_rej),\n",
    "    \"test\": (test_acc, test_rej),\n",
    "}\n",
    "\n",
    "for split, (acc_data, rej_data) in splits.items():\n",
    "    create_split_folder(os.path.join(output_dir, split), acc_data, \"Accepted\")\n",
    "    create_split_folder(os.path.join(output_dir, split), rej_data, \"Rejected\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fec45112-3de1-4f07-880e-e1f5fcbd96ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#### My simple 2 layer CNN\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(class_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_name' is not defined"
     ]
    }
   ],
   "source": [
    "#### My simple 2 layer CNN\n",
    "\n",
    "# Define transformations for preprocessing\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to VGG-16 input size\n",
    "        transforms.RandomHorizontalFlip(),  # Augmentation\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "        transforms.Normalize([0.5], [0.5])  # Normalize grayscale images\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c416387-c36d-403e-a1b5-d133cc37be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG-16 model and modify the classifier\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "num_features = vgg16.classifier[6].in_features\n",
    "vgg16.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 2),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "vgg16 = vgg16.to(DEVICE)\n",
    "\n",
    "# Define Adaptive gradient & X-entropy loss\n",
    "optimizer = optim.Adagrad(vgg16.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # re-train model\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "        train_acc.append(100.0 * correct / total)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        val_loss.append(running_loss / len(val_loader))\n",
    "        val_acc.append(100.0 * correct / total)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] -> Train Loss: {train_loss[-1]:.4f}, \"\n",
    "              f\"Train Acc: {train_acc[-1]:.2f}%, Val Loss: {val_loss[-1]:.4f}, Val Acc: {val_acc[-1]:.2f}%\")\n",
    "\n",
    "    return train_loss, val_loss, train_acc, val_acc\n",
    "\n",
    "# Train the model\n",
    "train_loss, val_loss, train_acc, val_acc = train_model(vgg16, criterion, optimizer, dataloaders[\"train\"], dataloaders[\"val\"], epochs=10)\n",
    "\n",
    "# Test function\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_acc = 100.0 * correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_acc = test_model(vgg16, dataloaders[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4acc5-ef52-4d1c-b545-a8485f4cf44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg16 = vgg16.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "best_model_wts = vgg16.state_dict()\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            vgg16.train()\n",
    "        else:\n",
    "            vgg16.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                outputs = vgg16(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        \n",
    "        print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "        \n",
    "        if phase == \"val\" and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = vgg16.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae80743-67fc-42ca-b78e-da5fe539b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "vgg16.eval()\n",
    "for inputs, labels in dataloaders[\"val\"]:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = vgg16(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
